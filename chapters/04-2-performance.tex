\section{Анализ производительности и масштабируемости}

Ключевым критерием эффективности навигационной системы является способность обрабатывать запросы пользователей с приемлемой задержкой (Soft Real-Time) даже в условиях пиковых нагрузок.

\subsection{Влияние «холодного старта» и дискового ввода-вывода}

В ходе Latency Test был выявлен значительный разброс времени отклика в зависимости от состояния кэша базы данных.
При первом запуске («холодный старт») время построения маршрута через всю Москву (МКАД Север $\to$ МКАД Юг, $\approx 45$ км) достигало \textbf{40 секунд}. Профилирование показало, что 92\% времени тратится на подъем данных с диска (NVMe SSD) в оперативную память. Алгоритм \texttt{pgr\_dijkstra} требует доступа к миллионам строк таблицы ребер, и даже быстрый SSD становится узким местом (IO Wait).

Однако при повторном запросе («прогретый кэш») время сокращалось до \textbf{2.5 секунд}. Это подтверждает эффективность механизма Shared Buffers в PostgreSQL\cite{osti_distributed_caching_2018}. В условиях высокой нагрузки мультиагентной системы это обеспечивает необходимую надежность\cite{almutairi2025reliable}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/images/latency_regression}
    \caption{Зависимость времени поиска от физического расстояния маршрута (log-log scale). Точки — отдельные запросы, линия — регрессионная модель.}
    \label{fig:latency-regression}
\end{figure}

Диаграмма рассеяния (рисунок~\ref{fig:latency-regression}) демонстрирует логарифмическую зависимость времени поиска от расстояния. Это достигается благодаря применению динамического ограничивающего прямоугольника (Dynamic BBOX).
Для коротких маршрутов (< 5 км) BBOX отсекает 99\% графа, и поиск занимает менее 100 мс. Для длинных маршрутов область поиска расширяется, но алгоритм все равно не сканирует весь граф целиком.

\subsection{Парадокс MVCC и вертикальная масштабируемость}

При проведении нагрузочного тестирования (Throughput Test) был зафиксирован неочевидный результат, названный «Парадоксом MVCC».
При увеличении количества параллельных клиентов с 1 до 16 (в соответствии с числом логических ядер CPU), среднее время отклика выросло всего на \textbf{9.7\%} (с 2.52 с до 2.76 с).
При этом утилизация процессора (CPU Load Average) выросла с 12\% до 87\%.

\begin{figure}[H]
    \centering
    \includemermaid[width=\linewidth, height=0.5\textheight, keepaspectratio]{04-mvcc-seq}
    \caption{Взаимодействие клиентов и БД в режиме конкурентности (MVCC)}
    \label{fig:mvcc-seq}
\end{figure}

Этот феномен объясняется архитектурой PostgreSQL:
\begin{itemize}
    \item Каждый запрос обслуживается отдельным процессом (Process-based architecture).
    \item Механизм MVCC (Multi-Version Concurrency Control) позволяет читающим транзакциям не блокировать друг друга (Readers never block readers).
    \item Асинхронный драйвер \texttt{asyncpg} эффективно мультиплексирует соединения, не создавая накладных расходов на переключение контекста в Python.
\end{itemize}

Таким образом, система демонстрирует практически линейную вертикальную масштабируемость вплоть до исчерпания ресурсов CPU.

\subsection{Анализ эффективности форматов передачи данных}

Сравнение объемов передаваемого трафика подтвердило необходимость использования бинарных форматов.
Текстовое представление геометрии (WKT, GeoJSON) приводит к раздуванию (Bloat) полезной нагрузки в 3-4 раза по сравнению с бинарными аналогами (WKB, MVT).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{assets/images/throughput_complexity_3d}
    \caption{3D-поверхность зависимости пропускной способности от размера запроса и сложности графа}
    \label{fig:throughput-complexity}
\end{figure}

Анализ поверхности производительности (рисунок~\ref{fig:throughput-complexity}) показывает, что переход на WKB (Binary) снижает накладные расходы на сериализацию на 70\% по сравнению с WKT, что особенно заметно на сложных маршрутах (>1000 вершин).

Для мобильных клиентов, работающих в сетях с нестабильным соединением (3G/LTE), экономия 70\% трафика является критическим преимуществом, напрямую влияющим на воспринимаемую скорость работы приложения (User Experience).
